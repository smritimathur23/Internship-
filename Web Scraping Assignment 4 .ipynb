{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ef0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import selenium \n",
    "from selenium import webdriver \n",
    "import time \n",
    "import requests \n",
    "import re \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException  \n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a98ea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudes\\AppData\\Local\\Temp/ipykernel_7116/179820662.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\sudes\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\sudes\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8256fc",
   "metadata": {},
   "source": [
    "# Question 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "    You need to find following details:\n",
    "    A) Rank\n",
    "    B) Name\n",
    "    C) Artist\n",
    "    D) Upload date\n",
    "    E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a7b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ba9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Upload_Date = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c00b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"): \n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Rank.append(\"__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d12c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"): \n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Name.append(\"__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c520bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\"): \n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Artist.append(\"__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbe1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"): \n",
    "        Upload_Date.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Upload_Date.append(\"__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24021781",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\"): \n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Views.append(\"__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ae39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikidata = pd.DataFrame()\n",
    "Wikidata['Rank'] = Rank[0:30] \n",
    "Wikidata['Name']=Name[0:30]\n",
    "Wikidata['Artist']=Artist[0:30]\n",
    "Wikidata['Upload Date']=Upload_Date[0:30]\n",
    "Wikidata['Views']=Views[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc507e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>11.58</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.99</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.50</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.83</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.68</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[16]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.68</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4.96</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.73</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.69</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[24]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.58</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[29]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.51</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.50</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.11</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.77</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.67</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.67</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.60</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Axel F\"[36]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.56</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[37]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.51</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[38]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.41</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.37</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.36</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.34</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.32</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.29</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.28</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Lean On\"[45]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.28</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.27</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.22</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.19</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                                  \"Bath Song\"[15]   \n",
       "5    6.                              \"See You Again\"[16]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.                                \"Uptown Funk\"[22]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "9   10.                              \"Gangnam Style\"[24]   \n",
       "10  11.   \"Masha and the Bear – Recipe for Disaster\"[29]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                                     \"Axel F\"[36]   \n",
       "18  18.                          \"Thinking Out Loud\"[37]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[38]   \n",
       "20  21.                                 \"Dark Horse\"[39]   \n",
       "21  22.                                      \"Faded\"[40]   \n",
       "22  23.                             \"Girls Like You\"[41]   \n",
       "23  24.                                 \"Let Her Go\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Perfect\"[44]   \n",
       "26  27.                                    \"Lean On\"[45]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "28  29.                               \"Shake It Off\"[47]   \n",
       "29  30.          \"Humpty the train on a fruits ride\"[48]   \n",
       "\n",
       "                                           Artist Upload Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories       11.58   \n",
       "1                                      Luis Fonsi        7.99   \n",
       "2                                     LooLoo Kids        6.50   \n",
       "3                                      Ed Sheeran        5.83   \n",
       "4                      Cocomelon – Nursery Rhymes        5.68   \n",
       "5                                     Wiz Khalifa        5.68   \n",
       "6                                       ChuChu TV        4.96   \n",
       "7                                     Mark Ronson        4.73   \n",
       "8                                     Miroshka TV        4.69   \n",
       "9                                             Psy        4.58   \n",
       "10                                     Get Movies        4.51   \n",
       "11                     Cocomelon – Nursery Rhymes        4.50   \n",
       "12                                      El Chombo        4.11   \n",
       "13                                       Maroon 5        3.77   \n",
       "14                                     Katy Perry        3.67   \n",
       "15                                    OneRepublic        3.67   \n",
       "16                                  Justin Bieber        3.60   \n",
       "17                                     Crazy Frog        3.56   \n",
       "18                                     Ed Sheeran        3.51   \n",
       "19                     Cocomelon – Nursery Rhymes        3.41   \n",
       "20                                     Katy Perry        3.37   \n",
       "21                                    Alan Walker        3.36   \n",
       "22                                       Maroon 5        3.34   \n",
       "23                                      Passenger        3.32   \n",
       "24                               Enrique Iglesias        3.29   \n",
       "25                                     Ed Sheeran        3.28   \n",
       "26                                    Major Lazer        3.28   \n",
       "27                                        Shakira        3.27   \n",
       "28                                   Taylor Swift        3.22   \n",
       "29  Kiddiestv Hindi – Nursery Rhymes & Kids Songs        3.19   \n",
       "\n",
       "                Views  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3    January 30, 2017  \n",
       "4         May 2, 2018  \n",
       "5       April 6, 2015  \n",
       "6       March 6, 2014  \n",
       "7   November 19, 2014  \n",
       "8   February 27, 2018  \n",
       "9       July 15, 2012  \n",
       "10   January 31, 2012  \n",
       "11       May 24, 2018  \n",
       "12      April 5, 2018  \n",
       "13   January 14, 2015  \n",
       "14  September 5, 2013  \n",
       "15       May 31, 2013  \n",
       "16   October 22, 2015  \n",
       "17      June 16, 2009  \n",
       "18    October 7, 2014  \n",
       "19      June 25, 2018  \n",
       "20  February 20, 2014  \n",
       "21   December 3, 2015  \n",
       "22       May 31, 2018  \n",
       "23      July 25, 2012  \n",
       "24     April 11, 2014  \n",
       "25   November 9, 2017  \n",
       "26     March 22, 2015  \n",
       "27       June 4, 2010  \n",
       "28    August 18, 2014  \n",
       "29   January 26, 2018  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752664d",
   "metadata": {},
   "source": [
    "# Question 2: Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "        You need to find following details:\n",
    "        A) Match title (I.e. 1st ODI)\n",
    "        B) Series\n",
    "        C) Place\n",
    "        D) Date\n",
    "        E) Time\n",
    "        Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fde69152",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49a9b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "International = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a') \n",
    "International.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0ff385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd0e3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH, \"//strong[@class='fixture__name fixture__name--with-margin']\"): \n",
    "    Match_Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f5abb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,\"//p[@class='fixture__additional-info']//span\"): \n",
    "    Place.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5587689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    series = driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[2]/section[3]/div/ul/li[1]/span[2]\")\n",
    "    Series.append(series.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18e621cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    date = driver.find_element(By.XPATH,\"//div[@class='mc-header-scorebox__datetime']//strong\")\n",
    "    Date.append(date.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89886260",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    times = driver.find_element(By.XPATH,\"//span[@class='mc-header-scorebox__ist-time']\")\n",
    "    Time.append(times.text)\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c6202b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[i.split(' ',3)[:3] for i in Date]\n",
    "date=[' '.join(i) for i in date]\n",
    "Time=[i.split(' ',3)[-1] for i in Date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dd00e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>__</td>\n",
       "      <td>__</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match Title Series Date Time\n",
       "0          NaN      -   __   __"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix=pd.DataFrame({})\n",
    "fix['Match Title'] = Match_Title\n",
    "fix['Series'] = Series\n",
    "fix['Date'] = Date\n",
    "fix['Time']= Time\n",
    "fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c59d12b",
   "metadata": {},
   "source": [
    "# Question 3. Scrape the details of selenium exception from guru99.com.\n",
    "        Url = https://www.guru99.com/\n",
    "        You need to find following details:\n",
    "        A) Name\n",
    "        B) Description\n",
    "        Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76f65c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.guru99.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "671147d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6cc5167",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"//li//a[@title='Selenium']\").click()\n",
    "driver.find_element(By.XPATH,'//a[@title=\"Selenium Exception Handling (Common Exceptions List)\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f6b8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,\"//table[@class='table table-striped']/tbody/tr/td[1]\"):\n",
    "            Name.append(i.text)\n",
    "\n",
    "#Scraping Description\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='table table-striped']/tbody/tr/td[2]\"):\n",
    "            Description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d410e93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception_Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Exception_Name, Description]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selenium=pd.DataFrame({})\n",
    "Selenium['Exception_Name']=Name\n",
    "Selenium['Description']=Description\n",
    "Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa45e7c",
   "metadata": {},
   "source": [
    "# Question 4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "    You have to find following details:\n",
    "    A) Rank\n",
    "    B) State\n",
    "    C) GSDP(18-19)\n",
    "    D) GSDP(17-18)\n",
    "    E) Share(2017)\n",
    "    F) GDP($ billion)\n",
    "    Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00b91098",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf5dd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = driver.find_element(By.XPATH,\"//div[@class='navbar']//div[2]//button\").click()\n",
    "urls = driver.find_element(By.XPATH,\"//div[@class='dropdown-content']//a[3]\")\n",
    "ineco_page = urls.get_attribute(\"href\")\n",
    "driver.get(ineco_page)  \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2df0b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDP_billion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86d04a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23ebf1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "570baeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "264cace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "561d0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b51e24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1feb0c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rank, State, GSDP at current price (19-20), GSDP at current price (18-19), Share(18-19),  GDP($ billion)]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP = pd.DataFrame({})\n",
    "GDP['Rank'] = Rank\n",
    "GDP['State'] = State\n",
    "GDP['GSDP at current price (19-20)'] = GSDP1\n",
    "GDP['GSDP at current price (18-19)'] = GSDP2\n",
    "GDP['Share(18-19)'] = Share\n",
    "GDP[' GDP($ billion)'] = GDP_billion\n",
    "GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01917afb",
   "metadata": {},
   "source": [
    "# Question 5. Scrape the details of trending repositories on Github.com.\n",
    "  \n",
    "        Url = https://github.com/\n",
    "        You have to find the following details:\n",
    "        A) Repository title\n",
    "        B) Repository description\n",
    "        C) Contributors count\n",
    "        D) Language used\n",
    "        Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc509f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc227cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "595247d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6321b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs = []\n",
    "Repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05f0241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository = driver.find_elements(By.XPATH,\"//h1[@class='h3 lh-condensed']//a\")\n",
    "for i in Repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8065d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    Repository_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c766c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    desc = driver.find_element(By.XPATH,\"//p[@class='f4 mt-3']\")\n",
    "    Description.append(desc.text)\n",
    "except NoSuchElementException:\n",
    "    Description.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8586f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    contributer = driver.find_element(By.XPATH,\"//*[contains(text(),'    Contributors ')]\")\n",
    "    Contributors.append(contributer.text.replace('Contributoers',''))\n",
    "except NoSuchElementException: \n",
    "    Contributors.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b4547a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = []\n",
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//ul[@class= 'list-style-none']//li//span[1]\"): \n",
    "        lang.append(i.text)\n",
    "    Language.append(lang)\n",
    "except NoSuchElementException: \n",
    "    Language.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e5b1e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>charmbracelet / vhs</td>\n",
       "      <td>-</td>\n",
       "      <td>_</td>\n",
       "      <td>[TypeScript, JavaScript, Shell, CSS]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Repository Title Repository Description Contributors Count  \\\n",
       "0  charmbracelet / vhs                      -                  _   \n",
       "\n",
       "                          Language Used  \n",
       "0  [TypeScript, JavaScript, Shell, CSS]  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB = pd.DataFrame({})\n",
    "GB['Repository Title'] = Repository_title[0:1]\n",
    "GB['Repository Description'] = Description[0:1]\n",
    "GB['Contributors Count'] = Contributors[0:1]\n",
    "GB['Language Used'] = Language[0:1]\n",
    "GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e059020",
   "metadata": {},
   "source": [
    "# Question 6. Scrape the details of top 100 songs on billboard.com.\n",
    "     Url = https://www.billboard.com/\n",
    "     You have to find the following details:\n",
    "     A) Song name\n",
    "     B) Artist name\n",
    "     C) Last week rank\n",
    "     D) Peak rank\n",
    "     E) Weeks on board\n",
    "      Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca9d938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63d24211",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"mega-menu-item-charts\"]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9878c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div/div[3]/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b8a50e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Songname = []\n",
    "Artistname = []\n",
    "Lastweekrank = []\n",
    "Peakrank = []\n",
    "Weeksonboard = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "338cd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//span[@class='chart-element__information__song text--truncate color--primary']\"): \n",
    "        Songname.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Songname.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0f4c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//span[@class='chart-element__information__artist text--truncate color--secondary']\"): \n",
    "        Artistname.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Artistname.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "feb0757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--last']\"): \n",
    "        Lastweekrank.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Lastweekrank.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "873499c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--peak']\"): \n",
    "        Peakrank.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Peakrank.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b900c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--week']\"): \n",
    "        Weeksonboard.append(i.text)\n",
    "except NoSuchElementException: \n",
    "    Weeksonboard.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c70293f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hot100Songs = pd.DataFrame({})\n",
    "Hot100Songs['Songs name'] = Songname[0:1]\n",
    "Hot100Songs['Artist name'] = Artistname[0:1]\n",
    "Hot100Songs['Last week rank'] = Lastweekrank[0:1]\n",
    "Hot100Songs['Peak rank'] = Peakrank[0:1]\n",
    "Hot100Songs['Weeks on board']  = Weeksonboard[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a87dcdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Songs name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Songs name             Artist name Last week rank Peak rank Weeks on board\n",
       "0             Sam Smith & Kim Petras              2         1              4"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hot100Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd50ebb",
   "metadata": {},
   "source": [
    "# Question 7. Scrape the details of Data science recruiters from naukri.com.\n",
    "  \n",
    "      Url = https://www.naukri.com/\n",
    "      You have to find the following details:\n",
    "      A) Name\n",
    "      B) Designation\n",
    "      C) Company\n",
    "      D) Skills they hire for\n",
    "      E) Location\n",
    "        Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b8cb3d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d4504",
   "metadata": {},
   "source": [
    "# Question 8. Scrape the details of Highest selling novels.\n",
    "      Url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "      You have to find the following details:\n",
    "      A) Book name\n",
    "      B) Author name\n",
    "      C) Volumes sold\n",
    "      D) Publisher\n",
    "      E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cfe38847",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "405ac786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book_name = []\n",
    "Author_name = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[2]\"):\n",
    "    Book_name.append(i.text)\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Author_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append('-')\n",
    "time.sleep(3)\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[4]\"):\n",
    "    Volumes_sold.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[6]\"):\n",
    "    Genre.append(i.text)    \n",
    "\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['Book Name'] = Book_name\n",
    "Novels['Author'] = Author_name\n",
    "Novels['Volume sold'] = Volumes_sold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8642e",
   "metadata": {},
   "source": [
    "# Question 9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "      Url = https://www.imdb.com/list/ls095964455/\n",
    "      You have to find the following details:\n",
    "      A) Name\n",
    "      B) Year span\n",
    "      C) Genre\n",
    "      D) Run time\n",
    "      E) Ratings\n",
    "      F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b2b9fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fb152fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,075,111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,165,948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>977,885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>291,186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>250,317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>196,389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>241,795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,075,111  \n",
       "1    51 min     8.7  1,165,948  \n",
       "2    44 min     8.1    977,885  \n",
       "3    60 min     7.5    291,186  \n",
       "4    43 min     7.6    250,317  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,905  \n",
       "96   50 min     7.8     61,012  \n",
       "97   42 min     8.1    196,389  \n",
       "98   45 min     7.1     41,366  \n",
       "99  572 min     8.6    241,795  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text) \n",
    "    \n",
    "TV_Series = pd.DataFrame({})\n",
    "TV_Series['Name'] = Name\n",
    "TV_Series['Year Span'] = Year_span\n",
    "TV_Series['Genre'] = Genre\n",
    "TV_Series['Run Time'] = Run_time\n",
    "TV_Series['Ratings'] = Ratings\n",
    "TV_Series['Votes'] = Votes\n",
    "TV_Series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
